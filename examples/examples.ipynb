{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook explains what `pandabear` is.\n",
    "\n",
    "> TL;DR: Library that makes it super easy to define schemas for your `pd.DataFrame`s and then actually *validate* dataframes against those schemas as they are passed in and out of functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's say you have some marketing performance data that looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spend_fb</th>\n",
       "      <th>impressions_fb</th>\n",
       "      <th>clicks_fb</th>\n",
       "      <th>spend_gads</th>\n",
       "      <th>impressions_gads</th>\n",
       "      <th>clicks_gads</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000</td>\n",
       "      <td>10000</td>\n",
       "      <td>100</td>\n",
       "      <td>4000</td>\n",
       "      <td>40000</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000</td>\n",
       "      <td>20000</td>\n",
       "      <td>200</td>\n",
       "      <td>5000</td>\n",
       "      <td>50000</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3000</td>\n",
       "      <td>30000</td>\n",
       "      <td>300</td>\n",
       "      <td>6000</td>\n",
       "      <td>60000</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   spend_fb  impressions_fb  clicks_fb  spend_gads  impressions_gads  \\\n",
       "0      1000           10000        100        4000             40000   \n",
       "1      2000           20000        200        5000             50000   \n",
       "2      3000           30000        300        6000             60000   \n",
       "\n",
       "   clicks_gads  \n",
       "0          400  \n",
       "1          500  \n",
       "2          600  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'spend_fb': [1000, 2000, 3000],\n",
    "    'impressions_fb': [10000, 20000, 30000],\n",
    "    'clicks_fb': [100, 200, 300],\n",
    "    'spend_gads': [4000, 5000, 6000],\n",
    "    'impressions_gads': [40000, 50000, 60000],\n",
    "    'clicks_gads': [400, 500, 600],\n",
    "})\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And somewhere in your pipeline you're dropping the `\"spend_\"` columns using a function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>impressions_fb</th>\n",
       "      <th>clicks_fb</th>\n",
       "      <th>impressions_gads</th>\n",
       "      <th>clicks_gads</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000</td>\n",
       "      <td>100</td>\n",
       "      <td>40000</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20000</td>\n",
       "      <td>200</td>\n",
       "      <td>50000</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30000</td>\n",
       "      <td>300</td>\n",
       "      <td>60000</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   impressions_fb  clicks_fb  impressions_gads  clicks_gads\n",
       "0           10000        100             40000          400\n",
       "1           20000        200             50000          500\n",
       "2           30000        300             60000          600"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def drop_spend(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Drop columns that contain the substring 'spend'\"\"\"\n",
    "    return df.drop(df.filter(regex='spend').columns, axis=1)\n",
    "\n",
    "drop_spend(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even with this simple example, if you don't know what `df` looks like when it comes *into* the function you will struggle to know its state when returned.\n",
    "\n",
    "**PROBLEM**: With complex dataframes and functions that **lack schema definitions**, it is **impossible to know** the state data as it is passed around in a pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pandabear` let's you\n",
    "1. Define dataframe schemas\n",
    "2. Pass those schemas to your function as type hints\n",
    "3. Decorate functions with a `check_schemas` decorator\n",
    "\n",
    "If you see this pattern in your code, you KNOW the state of the data by looking at the schema. **No more guessing or running the debugger to find out what a `df` contains!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>impressions_fb</th>\n",
       "      <th>clicks_fb</th>\n",
       "      <th>impressions_gads</th>\n",
       "      <th>clicks_gads</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000</td>\n",
       "      <td>100</td>\n",
       "      <td>40000</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20000</td>\n",
       "      <td>200</td>\n",
       "      <td>50000</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30000</td>\n",
       "      <td>300</td>\n",
       "      <td>60000</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   impressions_fb  clicks_fb  impressions_gads  clicks_gads\n",
       "0           10000        100             40000          400\n",
       "1           20000        200             50000          500\n",
       "2           30000        300             60000          600"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandabear as pb\n",
    "\n",
    "# 1. Define dataframe schemas (put this in a separate file to keep things clean)\n",
    "# ---------------------------\n",
    "\n",
    "class PlatformPerformanceMetrics(pb.DataFrameModel):\n",
    "    \"\"\"A model for platform performance data\"\"\"\n",
    "    spend_fb: int = pb.Field(ge=0)\n",
    "    impressions_fb: int = pb.Field(ge=0)\n",
    "    clicks_fb: int = pb.Field(ge=0)\n",
    "    spend_gads: int = pb.Field(ge=0)\n",
    "    impressions_gads: int = pb.Field(ge=0)\n",
    "    clicks_gads: int = pb.Field(ge=0)\n",
    "\n",
    "class AdPressureMetrics(pb.DataFrameModel):\n",
    "    \"\"\"A model for ad pressure data\"\"\"\n",
    "    impressions_fb: int = pb.Field(ge=0)\n",
    "    clicks_fb: int = pb.Field(ge=0)\n",
    "    impressions_gads: int = pb.Field(ge=0)\n",
    "    clicks_gads: int = pb.Field(ge=0)\n",
    "\n",
    "\n",
    "# 2-3. Pass schemas to function and decorate with `check_schemas`\n",
    "# ---------------------------------------------------------------\n",
    "\n",
    "@pb.check_schemas\n",
    "def drop_spend(df: pb.DataFrame[PlatformPerformanceMetrics]) -> pb.DataFrame[AdPressureMetrics]:\n",
    "    \"\"\"Drop columns that contain the substring 'spend'\"\"\"\n",
    "    return df.drop(df.filter(regex='spend').columns, axis=1)\n",
    "\n",
    "drop_spend(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using regex aliases\n",
    "\n",
    "The schema API allows for a much more concise way to define schemas, using aliases and regex! Basically, if you have lots of columns that are named similarly following some convention, you can define one field that matches them all using a regex alias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>impressions_fb</th>\n",
       "      <th>clicks_fb</th>\n",
       "      <th>impressions_gads</th>\n",
       "      <th>clicks_gads</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000</td>\n",
       "      <td>100</td>\n",
       "      <td>40000</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20000</td>\n",
       "      <td>200</td>\n",
       "      <td>50000</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30000</td>\n",
       "      <td>300</td>\n",
       "      <td>60000</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   impressions_fb  clicks_fb  impressions_gads  clicks_gads\n",
       "0           10000        100             40000          400\n",
       "1           20000        200             50000          500\n",
       "2           30000        300             60000          600"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Define dataframe schemas\n",
    "# ---------------------------\n",
    "\n",
    "class PlatformPerformanceMetrics(pb.DataFrameModel):\n",
    "    \"\"\"A model for platform performance data\"\"\"\n",
    "    spend: int = pb.Field(ge=0, alias=\"spend_.+\", regex=True)\n",
    "    impressions: int = pb.Field(ge=0, alias=\"impressions_.+\", regex=True)\n",
    "    clicks: int = pb.Field(ge=0, alias=\"clicks_.+\", regex=True)\n",
    "\n",
    "class AdPressureMetrics(pb.DataFrameModel):\n",
    "    \"\"\"A model for ad pressure data\"\"\"\n",
    "    impressions: int = pb.Field(ge=0, alias=\"impressions_.+\", regex=True)\n",
    "    clicks: int = pb.Field(ge=0, alias=\"clicks_.+\", regex=True)\n",
    "\n",
    "\n",
    "# 2-3. Pass schemas to function and decorate with `check_schemas`\n",
    "# ---------------------------------------------------------------\n",
    "\n",
    "@pb.check_schemas\n",
    "def drop_spend(df: pb.DataFrame[PlatformPerformanceMetrics]) -> pb.DataFrame[AdPressureMetrics]:\n",
    "    \"\"\"Drop columns that contain the substring 'spend'\"\"\"\n",
    "    return df.drop(df.filter(regex='spend').columns, axis=1)\n",
    "\n",
    "drop_spend(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coercing dtypes\n",
    "\n",
    "Sometimes you want to coerce dtypes of specific columns to be a certain type. For example, so far we have defined \"spend\" columns as `int`, but really they should be `float`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>impressions_fb</th>\n",
       "      <th>clicks_fb</th>\n",
       "      <th>impressions_gads</th>\n",
       "      <th>clicks_gads</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000</td>\n",
       "      <td>100</td>\n",
       "      <td>40000</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20000</td>\n",
       "      <td>200</td>\n",
       "      <td>50000</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30000</td>\n",
       "      <td>300</td>\n",
       "      <td>60000</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   impressions_fb  clicks_fb  impressions_gads  clicks_gads\n",
       "0           10000        100             40000          400\n",
       "1           20000        200             50000          500\n",
       "2           30000        300             60000          600"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Define dataframe schemas\n",
    "# ---------------------------\n",
    "\n",
    "class PlatformPerformanceMetrics(pb.DataFrameModel):\n",
    "    \"\"\"A model for platform performance data\"\"\"\n",
    "    spend: float = pb.Field(ge=0, alias=\"spend_.+\", regex=True, coerce=True)  # <--- LOOK HERE!\n",
    "    impressions: int = pb.Field(ge=0, alias=\"impressions_.+\", regex=True)\n",
    "    clicks: int = pb.Field(ge=0, alias=\"clicks_.+\", regex=True)\n",
    "\n",
    "class AdPressureMetrics(pb.DataFrameModel):\n",
    "    \"\"\"A model for ad pressure data\"\"\"\n",
    "    impressions: int = pb.Field(ge=0, alias=\"impressions_.+\", regex=True)\n",
    "    clicks: int = pb.Field(ge=0, alias=\"clicks_.+\", regex=True)\n",
    "\n",
    "\n",
    "# 2-3. Pass schemas to function and decorate with `check_schemas`\n",
    "# ---------------------------------------------------------------\n",
    "\n",
    "@pb.check_schemas\n",
    "def drop_spend(df: pb.DataFrame[PlatformPerformanceMetrics]) -> pb.DataFrame[AdPressureMetrics]:\n",
    "    \"\"\"Drop columns that contain the substring 'spend'\"\"\"\n",
    "    assert df.filter(regex='spend').iloc[:, 0].dtype == float  # <--- LOOK HERE!\n",
    "    return df.drop(df.filter(regex='spend').columns, axis=1)\n",
    "\n",
    "drop_spend(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Type coercing can also be defined on the schema-level by overriding the `Config` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlatformPerformanceMetrics(pb.DataFrameModel):\n",
    "    \"\"\"A model for platform performance data\"\"\"\n",
    "    spend: float = pb.Field(ge=0, alias=\"spend_.+\", regex=True)\n",
    "    impressions: int = pb.Field(ge=0, alias=\"impressions_.+\", regex=True)\n",
    "    clicks: int = pb.Field(ge=0, alias=\"clicks_.+\", regex=True)\n",
    "\n",
    "    class Config:\n",
    "        coerce = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This would apply coercing to all fields in the schema."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional fields"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When a column is defined in the schema, but is missing from the dataframe it will raise an error. But maybe this is not always desired. If you have optional columns you can use the `Optional` type, in the field definition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>impressions_fb</th>\n",
       "      <th>clicks_fb</th>\n",
       "      <th>impressions_gads</th>\n",
       "      <th>clicks_gads</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000</td>\n",
       "      <td>100</td>\n",
       "      <td>40000</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20000</td>\n",
       "      <td>200</td>\n",
       "      <td>50000</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30000</td>\n",
       "      <td>300</td>\n",
       "      <td>60000</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   impressions_fb  clicks_fb  impressions_gads  clicks_gads\n",
       "0           10000        100             40000          400\n",
       "1           20000        200             50000          500\n",
       "2           30000        300             60000          600"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Optional\n",
    "\n",
    "# 1. Define dataframe schemas\n",
    "# ---------------------------\n",
    "\n",
    "class PlatformPerformanceMetrics(pb.DataFrameModel):\n",
    "    \"\"\"A model for platform performance data\"\"\"\n",
    "    spend: Optional[float] = pb.Field(ge=0, alias=\"spend_.+\", regex=True)  # <--- LOOK HERE!\n",
    "    impressions: int = pb.Field(ge=0, alias=\"impressions_.+\", regex=True)\n",
    "    clicks: int = pb.Field(ge=0, alias=\"clicks_.+\", regex=True)\n",
    "\n",
    "    class Config:\n",
    "        coerce = True\n",
    "\n",
    "class AdPressureMetrics(pb.DataFrameModel):\n",
    "    \"\"\"A model for ad pressure data\"\"\"\n",
    "    impressions: int = pb.Field(ge=0, alias=\"impressions_.+\", regex=True)\n",
    "    clicks: int = pb.Field(ge=0, alias=\"clicks_.+\", regex=True)\n",
    "\n",
    "\n",
    "# 2-3. Pass schemas to function and decorate with `check_schemas`\n",
    "# ---------------------------------------------------------------\n",
    "\n",
    "@pb.check_schemas\n",
    "def drop_spend(df: pb.DataFrame[PlatformPerformanceMetrics]) -> pb.DataFrame[AdPressureMetrics]:\n",
    "    \"\"\"Drop columns that contain the substring 'spend'\"\"\"\n",
    "    return df.drop(df.filter(regex='spend').columns, axis=1)\n",
    "\n",
    "df_no_spend = drop_spend(df)  # df without 'spend_.+' columns...\n",
    "drop_spend(df_no_spend)       # not raising an error!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling unexpected columns\n",
    "If a column is defined in the schema (unless `Optional`) it MUST be present in the dataframe. But what about columns defined in the dataframe that are not in the schema?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Strict mode\n",
    "Unexpected columns in `df` will, by default, raise an error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "SchemaValidationError",
     "evalue": "Columns {'clicks_gads', 'clicks_fb'} are present in `df` but not in schema. Use `strict=False` or `filter=True` to supress this error.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mSchemaValidationError\u001b[0m                     Traceback (most recent call last)",
      "\u001b[1;32m/Users/ulfaslak/Documents/git/pandabear/examples/examples.ipynb Cell 25\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ulfaslak/Documents/git/pandabear/examples/examples.ipynb#X44sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Drop columns that contain the substring 'spend'\"\"\"\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ulfaslak/Documents/git/pandabear/examples/examples.ipynb#X44sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m df\u001b[39m.\u001b[39mdrop(df\u001b[39m.\u001b[39mfilter(regex\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mspend\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39mcolumns, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/ulfaslak/Documents/git/pandabear/examples/examples.ipynb#X44sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m drop_spend(df)  \u001b[39m# df without 'spend_.+' columns...\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/git/pandabear/src/pandabear/decorators.py:106\u001b[0m, in \u001b[0;36mcheck_schemas.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[39mfor\u001b[39;00m name, variable \u001b[39min\u001b[39;00m bound_args\u001b[39m.\u001b[39marguments\u001b[39m.\u001b[39mitems():\n\u001b[1;32m    105\u001b[0m     type_hint \u001b[39m=\u001b[39m sig\u001b[39m.\u001b[39mparameters[name]\u001b[39m.\u001b[39mannotation\n\u001b[0;32m--> 106\u001b[0m     bound_args\u001b[39m.\u001b[39marguments[name] \u001b[39m=\u001b[39m _validate_variable_against_type_hint(variable, type_hint, name)\n\u001b[1;32m    108\u001b[0m \u001b[39m# Extract `args` and `kwargs` from bound arguments\u001b[39;00m\n\u001b[1;32m    109\u001b[0m args \u001b[39m=\u001b[39m bound_args\u001b[39m.\u001b[39marguments\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39margs\u001b[39m\u001b[39m\"\u001b[39m, {})\n",
      "File \u001b[0;32m~/Documents/git/pandabear/src/pandabear/decorators.py:41\u001b[0m, in \u001b[0;36m_validate_variable_against_type_hint\u001b[0;34m(var, type_hint, name)\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[39mraise\u001b[39;00m TypeHintError(\n\u001b[1;32m     38\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mExpected `\u001b[39m\u001b[39m{\u001b[39;00mexpected_type\u001b[39m}\u001b[39;00m\u001b[39m[\u001b[39m\u001b[39m{\u001b[39;00mexpected_schema\u001b[39m}\u001b[39;00m\u001b[39m]` in \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39margument `\u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m`\u001b[39m\u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39mif\u001b[39;00m\u001b[39m \u001b[39mname\u001b[39m \u001b[39m\u001b[39m!=\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\u001b[39mreturn value\u001b[39m\u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39melse\u001b[39;00m\u001b[39m \u001b[39mname\u001b[39m}\u001b[39;00m\u001b[39m, but found \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(var)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m     39\u001b[0m         )\n\u001b[1;32m     40\u001b[0m     schema \u001b[39m=\u001b[39m get_args(type_hint)[\u001b[39m1\u001b[39m]\n\u001b[0;32m---> 41\u001b[0m     transformed_var \u001b[39m=\u001b[39m schema\u001b[39m.\u001b[39;49mvalidate(var)\n\u001b[1;32m     43\u001b[0m \u001b[39m# type hint like: `tuple[int, pd.DataFrame | MySchema]` (or deeper nesting)\u001b[39;00m\n\u001b[1;32m     44\u001b[0m \u001b[39melif\u001b[39;00m (\u001b[39mlen\u001b[39m(return_types \u001b[39m:=\u001b[39m get_args(type_hint))) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n",
      "File \u001b[0;32m~/Documents/git/pandabear/src/pandabear/model.py:435\u001b[0m, in \u001b[0;36mDataFrameModel.validate\u001b[0;34m(cls, df)\u001b[0m\n\u001b[1;32m    430\u001b[0m \u001b[39m# Check that indices and columns in `df` match schema. The only errors\u001b[39;00m\n\u001b[1;32m    431\u001b[0m \u001b[39m# that should be thrown here relate to schema errors or missing columns\u001b[39;00m\n\u001b[1;32m    432\u001b[0m \u001b[39m# in `df`. Furthermore, this method may filter, coerce or order `df`\u001b[39;00m\n\u001b[1;32m    433\u001b[0m \u001b[39m# depending on user-provided specifications in `Config`.\u001b[39;00m\n\u001b[1;32m    434\u001b[0m df \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_validate_multiindex(df, schema_map, Config)\n\u001b[0;32m--> 435\u001b[0m df \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_columns(df, schema_map, Config)\n\u001b[1;32m    437\u001b[0m \u001b[39m# Validate `df` against schema. The only errors that should be raised\u001b[39;00m\n\u001b[1;32m    438\u001b[0m \u001b[39m# in this step are from dtype checks and `Field` checks.\u001b[39;00m\n\u001b[1;32m    439\u001b[0m \u001b[39mfor\u001b[39;00m name, (typ, optional, is_index, field) \u001b[39min\u001b[39;00m schema_map\u001b[39m.\u001b[39mitems():\n\u001b[1;32m    440\u001b[0m     \u001b[39m# Select the column (or columns) in `df` that match the field.\u001b[39;00m\n\u001b[1;32m    441\u001b[0m     \u001b[39m# ... when index column\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/git/pandabear/src/pandabear/model.py:321\u001b[0m, in \u001b[0;36mDataFrameModel._validate_columns\u001b[0;34m(cls, df, schema_map, Config)\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[39melif\u001b[39;00m Config\u001b[39m.\u001b[39mstrict:\n\u001b[1;32m    320\u001b[0m     \u001b[39mif\u001b[39;00m unexpected_columns \u001b[39m:=\u001b[39m \u001b[39mset\u001b[39m(df\u001b[39m.\u001b[39mcolumns) \u001b[39m-\u001b[39m \u001b[39mset\u001b[39m(matching_columns_in_df):\n\u001b[0;32m--> 321\u001b[0m         \u001b[39mraise\u001b[39;00m SchemaValidationError(\n\u001b[1;32m    322\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mColumns \u001b[39m\u001b[39m{\u001b[39;00munexpected_columns\u001b[39m}\u001b[39;00m\u001b[39m are present in `df` but not in schema. Use `strict=False` or `filter=True` to supress this error.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    323\u001b[0m         )\n\u001b[1;32m    325\u001b[0m \u001b[39m# Complain if the order of columns in `df` does not match the order in\u001b[39;00m\n\u001b[1;32m    326\u001b[0m \u001b[39m# which they are defined in the schema\u001b[39;00m\n\u001b[1;32m    327\u001b[0m \u001b[39mif\u001b[39;00m Config\u001b[39m.\u001b[39mordered:\n",
      "\u001b[0;31mSchemaValidationError\u001b[0m: Columns {'clicks_gads', 'clicks_fb'} are present in `df` but not in schema. Use `strict=False` or `filter=True` to supress this error."
     ]
    }
   ],
   "source": [
    "# 1. Define dataframe schemas\n",
    "# ---------------------------\n",
    "\n",
    "class PlatformPerformanceMetrics(pb.DataFrameModel):\n",
    "    \"\"\"A model for platform performance data\"\"\"\n",
    "    spend: float = pb.Field(ge=0, alias=\"spend_.+\", regex=True)  # <--- LOOK HERE!\n",
    "    impressions: int = pb.Field(ge=0, alias=\"impressions_.+\", regex=True)\n",
    "    # clicks: int = pb.Field(ge=0, alias=\"clicks_.+\", regex=True)\n",
    "\n",
    "    class Config:\n",
    "        coerce = True\n",
    "\n",
    "class AdPressureMetrics(pb.DataFrameModel):\n",
    "    \"\"\"A model for ad pressure data\"\"\"\n",
    "    impressions: int = pb.Field(ge=0, alias=\"impressions_.+\", regex=True)\n",
    "    # clicks: int = pb.Field(ge=0, alias=\"clicks_.+\", regex=True)  # <--- LOOK HERE!\n",
    "\n",
    "\n",
    "# 2-3. Pass schemas to function and decorate with `check_schemas`\n",
    "# ---------------------------------------------------------------\n",
    "\n",
    "@pb.check_schemas\n",
    "def drop_spend(df: pb.DataFrame[PlatformPerformanceMetrics]) -> pb.DataFrame[AdPressureMetrics]:\n",
    "    \"\"\"Drop columns that contain the substring 'spend'\"\"\"\n",
    "    return df.drop(df.filter(regex='spend').columns, axis=1)\n",
    "\n",
    "drop_spend(df)  # df without 'spend_.+' columns..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This throws a `SchemaValidationError`, saying that some \"spend_\" columns are present in `df` but not in the schema. `strict=True` is the default, but if you want to allow for unexpected columns, you can simply set `strict=False` in the `Config` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>impressions_fb</th>\n",
       "      <th>clicks_fb</th>\n",
       "      <th>impressions_gads</th>\n",
       "      <th>clicks_gads</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000</td>\n",
       "      <td>100</td>\n",
       "      <td>40000</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20000</td>\n",
       "      <td>200</td>\n",
       "      <td>50000</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30000</td>\n",
       "      <td>300</td>\n",
       "      <td>60000</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   impressions_fb  clicks_fb  impressions_gads  clicks_gads\n",
       "0           10000        100             40000          400\n",
       "1           20000        200             50000          500\n",
       "2           30000        300             60000          600"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Define dataframe schemas\n",
    "# ---------------------------\n",
    "\n",
    "class PlatformPerformanceMetrics(pb.DataFrameModel):\n",
    "    \"\"\"A model for platform performance data\"\"\"\n",
    "    spend: float = pb.Field(ge=0, alias=\"spend_.+\", regex=True)  # <--- LOOK HERE!\n",
    "    impressions: int = pb.Field(ge=0, alias=\"impressions_.+\", regex=True)\n",
    "    # clicks: int = pb.Field(ge=0, alias=\"clicks_.+\", regex=True)\n",
    "\n",
    "    class Config:\n",
    "        coerce = True\n",
    "        strict = False # <--- LOOK HERE!\n",
    "\n",
    "class AdPressureMetrics(pb.DataFrameModel):\n",
    "    \"\"\"A model for ad pressure data\"\"\"\n",
    "    impressions: int = pb.Field(ge=0, alias=\"impressions_.+\", regex=True)\n",
    "    # clicks: int = pb.Field(ge=0, alias=\"clicks_.+\", regex=True)  # <--- LOOK HERE!\n",
    "\n",
    "    class Config:\n",
    "        strict = False # <--- LOOK HERE!\n",
    "\n",
    "\n",
    "# 2-3. Pass schemas to function and decorate with `check_schemas`\n",
    "# ---------------------------------------------------------------\n",
    "\n",
    "@pb.check_schemas\n",
    "def drop_spend(df: pb.DataFrame[PlatformPerformanceMetrics]) -> pb.DataFrame[AdPressureMetrics]:\n",
    "    \"\"\"Drop columns that contain the substring 'spend'\"\"\"\n",
    "    return df.drop(df.filter(regex='spend').columns, axis=1)\n",
    "\n",
    "drop_spend(df)  # df without 'spend_.+' columns..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filter mode\n",
    "Another way to deal with unexpected columns, is to just remove them, so they never enter/exit the function. This is done by setting `filter=True` in the `Config` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>impressions_fb</th>\n",
       "      <th>impressions_gads</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000</td>\n",
       "      <td>40000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20000</td>\n",
       "      <td>50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30000</td>\n",
       "      <td>60000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   impressions_fb  impressions_gads\n",
       "0           10000             40000\n",
       "1           20000             50000\n",
       "2           30000             60000"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Define dataframe schemas\n",
    "# ---------------------------\n",
    "\n",
    "class PlatformPerformanceMetrics(pb.DataFrameModel):\n",
    "    \"\"\"A model for platform performance data\"\"\"\n",
    "    spend: float = pb.Field(ge=0, alias=\"spend_.+\", regex=True)  # <--- LOOK HERE!\n",
    "    impressions: int = pb.Field(ge=0, alias=\"impressions_.+\", regex=True)\n",
    "    # clicks: int = pb.Field(ge=0, alias=\"clicks_.+\", regex=True)\n",
    "\n",
    "    class Config:\n",
    "        coerce = True\n",
    "        filter = True # <--- LOOK HERE!\n",
    "\n",
    "class AdPressureMetrics(pb.DataFrameModel):\n",
    "    \"\"\"A model for ad pressure data\"\"\"\n",
    "    impressions: int = pb.Field(ge=0, alias=\"impressions_.+\", regex=True)\n",
    "    # clicks: int = pb.Field(ge=0, alias=\"clicks_.+\", regex=True)  # <--- LOOK HERE!\n",
    "\n",
    "\n",
    "# 2-3. Pass schemas to function and decorate with `check_schemas`\n",
    "# ---------------------------------------------------------------\n",
    "\n",
    "@pb.check_schemas\n",
    "def drop_spend(df: pb.DataFrame[PlatformPerformanceMetrics]) -> pb.DataFrame[AdPressureMetrics]:\n",
    "    \"\"\"Drop columns that contain the substring 'spend'\"\"\"\n",
    "    assert not df.filter(regex='clicks').columns.tolist(), \"`pandabear` filtered these out in this example!\"\n",
    "    return df.drop(df.filter(regex='spend').columns, axis=1)\n",
    "\n",
    "drop_spend(df)  # df without 'spend_.+' columns..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `\"clicks_*\"` columns filtered before the enter the function, and so they are also not returned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FAQ\n",
    "\n",
    "**What is `pandabear`?**\n",
    "> `pandabear` is a runtime pandas data- and schema validator. It is a lightweight alternative to [pandera](https://github.com/unionai-oss/pandera), with an almost identical API.\n",
    "\n",
    "**What is `pandabear` not?**\n",
    "> `pandabear` is not a statistical testing library. It is not a data validation library. It is not a type checker. It is not a linter. It is not a static validator. It is not a schema generator. It is not a data generator. It is not a data profiler. It is not a data transformer. It is not a data visualizer. It is not a data explorer.\n",
    ">\n",
    "> ... it just checks if your dataframes match their schemas.\n",
    "\n",
    "**Why use it?**\n",
    "> Because it has a really simple API that anyone can understand, and adds little to no complexity to code. And because tells developers exactly what data is being passed around in a pipeline, without having to run the code.\n",
    "\n",
    "**What is a schema?**\n",
    "> A schema defines the structure of a pandas dataframe. It is a set of rules that a dataframe must follow in order to be considered valid. At the core of a schema definition is the `Field`. A `Field` is a single rule that a column—or group of columns—must follow. Here is an example of a `Field`:\n",
    "> ```python\n",
    "> clicks: int = Field(ge=0, le=100)\n",
    "> ```\n",
    "> This `Field` says that the column `clicks` must be an integer between 0 and 100. A schema typically has multiple such fields that define the structure of a dataframe. Fields can also match multiple columns, using the `regex` argument:\n",
    "> ```python\n",
    "> clicks: int = Field(regex=\"clicks_.+\", ge=0, le=100)\n",
    "> ```\n",
    "> This `Field` says that all columns that match the regex `clicks_.+` must be integers between 0 and 100. This is a very powerful feature that allows you to define schemas for dataframes with many columns, without having to define a `Field` for each column.\n",
    ">\n",
    "> Here is an example of a simple schema:\n",
    "> ```python\n",
    "> class MySimpleSchema(pandabear.DataFrameModel):\n",
    ">     spend: float = Field(ge=0)\n",
    ">     clicks: int = Field(ge=0)\n",
    ">     impressions: int = Field(ge=0)\n",
    ">     conversions: int = Field(ge=0)\n",
    "> ```\n",
    "> This schema says that a dataframe must have the columns `spend`, `clicks`, `impressions`, and `conversions`, and that all these columns must be non-negative integers or floats.\n",
    ">\n",
    "> Here is an example of a more complex schema:\n",
    "> ```python\n",
    "> class MyComplexSchema(pandabear.DataFrameModel):\n",
    ">     geo_zone: Index[str] = Field(unique=True)\n",
    ">     date: Index[Datetime]  # yes, you can have multiple dataframe indexes!\n",
    ">     spend: float = Field(alias=\"spend___.+\", regex=True, ge=0)\n",
    ">     clicks: int = Field(alias=\"clicks___.+\", regex=True, ge=0)\n",
    ">     impressions: int = Field(alias=\"impressions___.+\", regex=True, ge=0)\n",
    ">     conversions: int = Field(alias=\"conversions___.+\", regex=True, ge=0)\n",
    ">     cpa: Optional[float] = Field(alias=\"cpa___.+\", regex=True, ge=0)\n",
    ">     ctr: Optional[float] = Field(alias=\"cpc___.+\", regex=True, ge=0, le=1)\n",
    ">\n",
    ">     @check('date')\n",
    ">     def check_date_is_ordered(se: pd.Series) -> bool:\n",
    ">         return se.is_monotonic_increasing\n",
    ">   \n",
    ">     @check('cpa')\n",
    ">     def check_cpa_is_valid(se: pd.Series) -> bool:\n",
    ">         return se.mean() < 1000\n",
    ">\n",
    ">     class Config:\n",
    ">         filter = True\n",
    ">         coerce = True\n",
    "> ```\n",
    "> This schema says that a dataframe must have the indexes `geo_zone` and `date`, and columns `spend`, `clicks`, `impressions`, `conversions`, `cpa`, and `ctr`. The indexes must be unique strings and datetimes, respectively. The columns must be non-negative integers or floats, except for `ctr` which must be between 0 and 1. Each column field is aliased to match multiple columns using regex (in `df` there may be \"spend___fb\", \"spend___gads\", etc.). The `cpa` and `ctr` columns are optional. Then there are custom checks saying the `date` index must be ordered and `cpa` must have a mean less than 1000.\n",
    "\n",
    "\n",
    "\n",
    "**What is a runtime validator?**\n",
    "> A runtime validator is called at runtime, meaning that it is called when the code is executed. This is in contrast to a static validator, which is called when the code is compiled. For example, if one defines a schema check using `pandabear` like so:\n",
    "> ```python\n",
    "> @check_schemas\n",
    "> def my_function(df: DataFrame[MySchema]):\n",
    ">     ...\n",
    "> my_function(df)\n",
    "> ```\n",
    "> and `df` fails the check, then an error is throw when `my_function(df)` is executed (not when the function is defined).\n",
    "\n",
    "\n",
    "**What does it support?**\n",
    "> You can specify schemas to match *nearly* any form of `pd.DataFrame` data. It supports specifying:\n",
    "> * Column names (optionally with regex to match multiple columns)\n",
    "> * Column dtypes\n",
    "> * Optional columns\n",
    "> * Indexes (multiple index levels are also supported)\n",
    "> * Index data types\n",
    "> * Optional indexes\n",
    "> * Simple statistical checks (e.g. `ge`, `le`, `gt`, `lt`, `eq`, `ne`)\n",
    "> * Custom column checks (e.g. `lambda x: x.mean() > 999`)\n",
    "> * Custom dataframe checks (e.g. `lambda df: df[\"spend\"]/df[\"clicks\"].mean() < 1000`)\n",
    "> * Coercing dtypes\n",
    "> * Filtering columns (at runtime, remove `df` columns that are not in the schema)\n",
    "> * All the above, but for `pd.Series`.\n",
    "> * more ...\n",
    "\n",
    "**What does it not support?**\n",
    "> * Multi-index columns. Fringe, too complicated. Let us know if you need it!\n",
    "> \n",
    "\n",
    "**Why not just use `pandera`?**\n",
    ">Because `pandera` really an extensive statistical testing library. Runtime schema validation is just a minor feature. Also it has some problems:\n",
    ">* Single core developer\n",
    ">* 4,249 dependencies [2023-10-23]\n",
    ">* 263 open issues (97 bugs) [as of 2023-10-23]\n",
    ">* It doesn't play nice with other runtime type checkers\n",
    "\n",
    "**Why not just use `pydantic`?**\n",
    ">Because `pydantic` is a data validation library, not a pandas dataframe validation library. It has a more versatile API and it not as easy to use as `pandabear`.\n",
    "\n",
    "**How do I use it in practice?**\n",
    "> It's up to you. We (Pierre and Ulf) typically define schemas in a `schemas.py` file, and then import them where necessary. Then we decoreate functions with `@check_schemas` and pass the schemas as type hints. But you can also define schemas in the same file as the function, or even inline in the function definition (but don't, ok). It's up to you.\n",
    ">\n",
    "> We designed it to have as minimal a footprint as possible. But you will have to add the `@check_schemas` decorators in your code, and you will have to pass the schemas as type hints. But that's it. No other changes to your code are necessary.\n",
    "\n",
    "**Does it work with other runtime type checkers?**\n",
    "> Yes! At least it should. The trick we use to enable this is to let `pb.DataFrame[MySchema]` evaluate to `pd.DataFrame | MySchema`, so that `isinstance(df, pb.DataFrame[MySchema]) == True`. We have tested it with `beartype` (our favorite). But it should work with `pydantic`, `dataclasses`, `typing`, etc. If you find a bug, please let us know!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
